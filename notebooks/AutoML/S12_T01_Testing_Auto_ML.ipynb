{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "# Folder configuration\n",
    "# ==============================================================================\n",
    "from os import path\n",
    "import sys\n",
    "new_path = '../../scripts/'\n",
    "if new_path not in sys.path:\n",
    "    sys.path.append(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyAutoMLClassifier:\n",
    "  def __init__(self, scoring_function = 'balanced_accuracy', n_iter = 50):\n",
    "    self.scoring_function = scoring_function\n",
    "    self.n_iter = n_iter\n",
    "  \n",
    "  def fit(self,X,y):\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "\n",
    "    categorical_values = []\n",
    "\n",
    "    cat_subset = X_train.select_dtypes(include = ['object','category','bool'])\n",
    "\n",
    "    for i in range(cat_subset.shape[1]):\n",
    "      categorical_values.append(list(cat_subset.iloc[:,i].dropna().unique()))\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "                         ('cleaner',SimpleImputer()),\n",
    "                         ('scaler',StandardScaler())\n",
    "                         ])\n",
    "\n",
    "    cat_pipeline = Pipeline([\n",
    "                        ('cleaner',SimpleImputer(strategy = 'most_frequent')),\n",
    "                        ('encoder',OneHotEncoder(sparse = False, categories=categorical_values))\n",
    "    ])\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "      ('numerical', num_pipeline, make_column_selector(dtype_exclude=['object','category','bool'])),\n",
    "      ('categorical', cat_pipeline, make_column_selector(dtype_include=['object','category','bool']))\n",
    "    ])\n",
    "\n",
    "    model_pipeline_steps = []\n",
    "    model_pipeline_steps.append(('preprocessor',preprocessor))\n",
    "    model_pipeline_steps.append(('feature_selector',SelectKBest(f_classif,k='all')))\n",
    "    model_pipeline_steps.append(('estimator',LogisticRegression()))\n",
    "    model_pipeline = Pipeline(model_pipeline_steps)\n",
    "\n",
    "    total_features = preprocessor.fit_transform(X_train).shape[1]\n",
    "\n",
    "    optimization_grid = []\n",
    "\n",
    "    # Logistic regression\n",
    "    optimization_grid.append({\n",
    "        'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
    "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
    "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
    "        'estimator':[LogisticRegression()]\n",
    "    })\n",
    "\n",
    "    # K-nearest neighbors\n",
    "    optimization_grid.append({\n",
    "        'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
    "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
    "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
    "        'estimator':[KNeighborsClassifier()],\n",
    "        'estimator__weights':['uniform','distance'],\n",
    "        'estimator__n_neighbors':np.arange(1,20,1)\n",
    "    })\n",
    "\n",
    "    # Random Forest\n",
    "    optimization_grid.append({\n",
    "        'preprocessor__numerical__scaler':[None],\n",
    "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
    "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
    "        'estimator':[RandomForestClassifier(random_state=0)],\n",
    "        'estimator__n_estimators':np.arange(5,500,10),\n",
    "        'estimator__criterion':['gini','entropy']\n",
    "    })\n",
    "\n",
    "\n",
    "    # Gradient boosting\n",
    "    optimization_grid.append({\n",
    "        'preprocessor__numerical__scaler':[None],\n",
    "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
    "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
    "        'estimator':[GradientBoostingClassifier(random_state=0)],\n",
    "        'estimator__n_estimators':np.arange(5,500,10),\n",
    "        'estimator__learning_rate':np.linspace(0.1,0.9,20),\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    # Decision tree\n",
    "    optimization_grid.append({\n",
    "        'preprocessor__numerical__scaler':[None],\n",
    "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
    "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
    "        'estimator':[DecisionTreeClassifier(random_state=0)],\n",
    "        'estimator__criterion':['gini','entropy']\n",
    "    })\n",
    "\n",
    "    # Linear SVM\n",
    "    optimization_grid.append({\n",
    "        'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
    "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
    "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
    "        'estimator':[LinearSVC(random_state = 0)],\n",
    "        'estimator__C': np.arange(0.1,1,0.1),\n",
    "        \n",
    "    })\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "      model_pipeline,\n",
    "      optimization_grid,\n",
    "      n_iter=self.n_iter,\n",
    "      scoring = self.scoring_function, \n",
    "      n_jobs = -1, \n",
    "      random_state = 0, \n",
    "      verbose = 3,\n",
    "      cv = 5\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    self.best_estimator_ = search.best_estimator_\n",
    "    self.best_pipeline = search.best_params_\n",
    "    \n",
    "\n",
    "  \n",
    "  def predict(self,X,y = None):\n",
    "    return self.best_estimator_.predict(X)\n",
    "\n",
    "  def predict_proba(self,X,y = None):\n",
    "    return self.best_estimator_.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path folder configuration\n",
    "# ===============================================================================\n",
    "\n",
    "path = '../../data/'\n",
    "file = 'raw/DelayedFlights.csv'\n",
    "\n",
    "d = pd.read_csv(path+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.drop(labels='Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.loc[:,[\"ArrDelay\",\"ArrTime\",\"AirTime\", \"Distance\", \"TaxiIn\", \"TaxiOut\", \"DayOfWeek\", \"DepDelay\",\"CarrierDelay\", 'UniqueCarrier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.sample(frac=0.00001, random_state = 6858)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         ArrDelay  ArrTime  AirTime  Distance  TaxiIn  TaxiOut  DayOfWeek  \\\n",
       "32721        81.0   1417.0     56.0       370     6.0     13.0          2   \n",
       "480545       26.0   1932.0    100.0       317    12.0     17.0          4   \n",
       "879313       20.0   1031.0    302.0      2105     8.0     18.0          1   \n",
       "1670776      16.0   1731.0     42.0       236     7.0     14.0          6   \n",
       "1464310     173.0   2322.0    280.0      2367     6.0     10.0          5   \n",
       "831723       20.0   1800.0     45.0       296     4.0     24.0          1   \n",
       "1770785     -16.0   2219.0     75.0       585     4.0      8.0          2   \n",
       "681387       17.0   1457.0    129.0       957     5.0     22.0          7   \n",
       "1909246       6.0   1941.0     37.0       190     3.0     16.0          3   \n",
       "1338544      16.0   1712.0     97.0       678     5.0     34.0          4   \n",
       "372328       28.0   2142.0     32.0       191     7.0     28.0          2   \n",
       "881487       18.0   1653.0     73.0       576     4.0     14.0          4   \n",
       "1022288      14.0   2242.0     49.0       334    11.0     14.0          2   \n",
       "549484        9.0   1824.0    145.0       987     8.0      8.0          6   \n",
       "805369      125.0   1922.0    112.0       759     9.0     44.0          6   \n",
       "878507       29.0   1609.0     42.0       214     3.0     45.0          4   \n",
       "1723086     122.0   1906.0    288.0      2465     9.0     10.0          4   \n",
       "828262        5.0   1010.0     58.0       364    12.0     12.0          7   \n",
       "558495       -9.0   1029.0    158.0      1091     5.0     10.0          5   \n",
       "\n",
       "         DepDelay  CarrierDelay UniqueCarrier  \n",
       "32721        92.0           0.0            XE  \n",
       "480545        8.0           8.0            EV  \n",
       "879313       13.0           0.0            DL  \n",
       "1670776      29.0           0.0            UA  \n",
       "1464310     176.0           0.0            UA  \n",
       "831723       22.0           5.0            MQ  \n",
       "1770785      12.0           NaN            WN  \n",
       "681387        7.0           7.0            NW  \n",
       "1909246      10.0           NaN            AA  \n",
       "1338544       6.0           0.0            US  \n",
       "372328       24.0          24.0            DL  \n",
       "881487       37.0           7.0            DL  \n",
       "1022288      13.0           NaN            NW  \n",
       "549484       15.0           NaN            AS  \n",
       "805369       98.0           0.0            US  \n",
       "878507       10.0          10.0            DL  \n",
       "1723086     129.0          19.0            B6  \n",
       "828262        8.0           NaN            MQ  \n",
       "558495       11.0           NaN            CO  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArrDelay</th>\n      <th>ArrTime</th>\n      <th>AirTime</th>\n      <th>Distance</th>\n      <th>TaxiIn</th>\n      <th>TaxiOut</th>\n      <th>DayOfWeek</th>\n      <th>DepDelay</th>\n      <th>CarrierDelay</th>\n      <th>UniqueCarrier</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32721</th>\n      <td>81.0</td>\n      <td>1417.0</td>\n      <td>56.0</td>\n      <td>370</td>\n      <td>6.0</td>\n      <td>13.0</td>\n      <td>2</td>\n      <td>92.0</td>\n      <td>0.0</td>\n      <td>XE</td>\n    </tr>\n    <tr>\n      <th>480545</th>\n      <td>26.0</td>\n      <td>1932.0</td>\n      <td>100.0</td>\n      <td>317</td>\n      <td>12.0</td>\n      <td>17.0</td>\n      <td>4</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>EV</td>\n    </tr>\n    <tr>\n      <th>879313</th>\n      <td>20.0</td>\n      <td>1031.0</td>\n      <td>302.0</td>\n      <td>2105</td>\n      <td>8.0</td>\n      <td>18.0</td>\n      <td>1</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>DL</td>\n    </tr>\n    <tr>\n      <th>1670776</th>\n      <td>16.0</td>\n      <td>1731.0</td>\n      <td>42.0</td>\n      <td>236</td>\n      <td>7.0</td>\n      <td>14.0</td>\n      <td>6</td>\n      <td>29.0</td>\n      <td>0.0</td>\n      <td>UA</td>\n    </tr>\n    <tr>\n      <th>1464310</th>\n      <td>173.0</td>\n      <td>2322.0</td>\n      <td>280.0</td>\n      <td>2367</td>\n      <td>6.0</td>\n      <td>10.0</td>\n      <td>5</td>\n      <td>176.0</td>\n      <td>0.0</td>\n      <td>UA</td>\n    </tr>\n    <tr>\n      <th>831723</th>\n      <td>20.0</td>\n      <td>1800.0</td>\n      <td>45.0</td>\n      <td>296</td>\n      <td>4.0</td>\n      <td>24.0</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>5.0</td>\n      <td>MQ</td>\n    </tr>\n    <tr>\n      <th>1770785</th>\n      <td>-16.0</td>\n      <td>2219.0</td>\n      <td>75.0</td>\n      <td>585</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>2</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>WN</td>\n    </tr>\n    <tr>\n      <th>681387</th>\n      <td>17.0</td>\n      <td>1457.0</td>\n      <td>129.0</td>\n      <td>957</td>\n      <td>5.0</td>\n      <td>22.0</td>\n      <td>7</td>\n      <td>7.0</td>\n      <td>7.0</td>\n      <td>NW</td>\n    </tr>\n    <tr>\n      <th>1909246</th>\n      <td>6.0</td>\n      <td>1941.0</td>\n      <td>37.0</td>\n      <td>190</td>\n      <td>3.0</td>\n      <td>16.0</td>\n      <td>3</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>AA</td>\n    </tr>\n    <tr>\n      <th>1338544</th>\n      <td>16.0</td>\n      <td>1712.0</td>\n      <td>97.0</td>\n      <td>678</td>\n      <td>5.0</td>\n      <td>34.0</td>\n      <td>4</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>372328</th>\n      <td>28.0</td>\n      <td>2142.0</td>\n      <td>32.0</td>\n      <td>191</td>\n      <td>7.0</td>\n      <td>28.0</td>\n      <td>2</td>\n      <td>24.0</td>\n      <td>24.0</td>\n      <td>DL</td>\n    </tr>\n    <tr>\n      <th>881487</th>\n      <td>18.0</td>\n      <td>1653.0</td>\n      <td>73.0</td>\n      <td>576</td>\n      <td>4.0</td>\n      <td>14.0</td>\n      <td>4</td>\n      <td>37.0</td>\n      <td>7.0</td>\n      <td>DL</td>\n    </tr>\n    <tr>\n      <th>1022288</th>\n      <td>14.0</td>\n      <td>2242.0</td>\n      <td>49.0</td>\n      <td>334</td>\n      <td>11.0</td>\n      <td>14.0</td>\n      <td>2</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>NW</td>\n    </tr>\n    <tr>\n      <th>549484</th>\n      <td>9.0</td>\n      <td>1824.0</td>\n      <td>145.0</td>\n      <td>987</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>6</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>AS</td>\n    </tr>\n    <tr>\n      <th>805369</th>\n      <td>125.0</td>\n      <td>1922.0</td>\n      <td>112.0</td>\n      <td>759</td>\n      <td>9.0</td>\n      <td>44.0</td>\n      <td>6</td>\n      <td>98.0</td>\n      <td>0.0</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>878507</th>\n      <td>29.0</td>\n      <td>1609.0</td>\n      <td>42.0</td>\n      <td>214</td>\n      <td>3.0</td>\n      <td>45.0</td>\n      <td>4</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>DL</td>\n    </tr>\n    <tr>\n      <th>1723086</th>\n      <td>122.0</td>\n      <td>1906.0</td>\n      <td>288.0</td>\n      <td>2465</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>4</td>\n      <td>129.0</td>\n      <td>19.0</td>\n      <td>B6</td>\n    </tr>\n    <tr>\n      <th>828262</th>\n      <td>5.0</td>\n      <td>1010.0</td>\n      <td>58.0</td>\n      <td>364</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>7</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>MQ</td>\n    </tr>\n    <tr>\n      <th>558495</th>\n      <td>-9.0</td>\n      <td>1029.0</td>\n      <td>158.0</td>\n      <td>1091</td>\n      <td>5.0</td>\n      <td>10.0</td>\n      <td>5</td>\n      <td>11.0</td>\n      <td>NaN</td>\n      <td>CO</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import categorical \n",
    "\n",
    "d = categorical.transform(d, \"UniqueCarrier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "d.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = d['ArrDelay']\n",
    "X = d.drop('ArrDelay', axis = 'columns')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "auto-sklearn results:\n  Dataset name: c8b28a39-c9ff-11eb-806e-03f13631734a\n  Metric: r2\n  Best validation score: 0.962278\n  Number of target algorithm runs: 48\n  Number of successful target algorithm runs: 46\n  Number of crashed target algorithm runs: 2\n  Number of target algorithms that exceeded the time limit: 0\n  Number of target algorithms that exceeded the memory limit: 0\n\n"
     ]
    }
   ],
   "source": [
    "import autosklearn.regression\n",
    "#ask.classification.AutoSklearnClassifier\n",
    "#ask.regression.AutoSklearnRegressor() for regression tasks\n",
    "model = autosklearn.regression.AutoSklearnRegressor(ensemble_size=10, #size of the end ensemble (minimum is 1)\n",
    "                                                 time_left_for_this_task=120, #the number of seconds the process runs for\n",
    "                                                 per_run_time_limit=30) #maximum seconds allocated per model\n",
    "model.fit(X_train, y_train) #begin fitting the search model\n",
    "print(model.sprint_statistics()) #print statistics for the search\n",
    "y_predictions = model.predict(X_test) #get predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting deap\n",
      "  Downloading deap-1.3.1-cp38-cp38-manylinux2010_x86_64.whl (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 1.8 MB/s \n",
      "\u001b[?25hCollecting update_checker\n",
      "  Using cached update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: tqdm in /home/jesus/.local/lib/python3.8/site-packages (4.56.0)\n",
      "Processing /home/jesus/.cache/pip/wheels/a8/bb/8f/6b9328d23c2dcedbfeb8498b9f650d55d463089e3b8fc0bfb2/stopit-1.1.2-py3-none-any.whl\n",
      "Requirement already satisfied: xgboost in /home/jesus/.local/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy in /home/jesus/.local/lib/python3.8/site-packages (from deap) (1.19.1)\n",
      "Requirement already satisfied: requests>=2.3.0 in /home/jesus/.local/lib/python3.8/site-packages (from update_checker) (2.25.1)\n",
      "Requirement already satisfied: scipy in /home/jesus/.local/lib/python3.8/site-packages (from xgboost) (1.5.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.3.0->update_checker) (2019.11.28)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests>=2.3.0->update_checker) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.3.0->update_checker) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.3.0->update_checker) (1.25.8)\n",
      "Installing collected packages: deap, update-checker, stopit\n",
      "Successfully installed deap-1.3.1 stopit-1.1.2 update-checker-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install deap update_checker tqdm stopit xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tpot\n",
      "  Downloading TPOT-0.11.7-py3-none-any.whl (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 526 kB/s \n",
      "\u001b[?25hRequirement already satisfied: deap>=1.2 in /home/jesus/.local/lib/python3.8/site-packages (from tpot) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /home/jesus/.local/lib/python3.8/site-packages (from tpot) (0.24.2)\n",
      "Requirement already satisfied: stopit>=1.1.1 in /home/jesus/.local/lib/python3.8/site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /home/jesus/.local/lib/python3.8/site-packages (from tpot) (1.0.0)\n",
      "Requirement already satisfied: update-checker>=0.16 in /home/jesus/.local/lib/python3.8/site-packages (from tpot) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /home/jesus/.local/lib/python3.8/site-packages (from tpot) (1.19.1)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /home/jesus/.local/lib/python3.8/site-packages (from tpot) (4.56.0)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /home/jesus/.local/lib/python3.8/site-packages (from tpot) (1.5.4)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in /home/jesus/.local/lib/python3.8/site-packages (from tpot) (1.1.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /home/jesus/.local/lib/python3.8/site-packages (from tpot) (1.0.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jesus/.local/lib/python3.8/site-packages (from scikit-learn>=0.22.0->tpot) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in /home/jesus/.local/lib/python3.8/site-packages (from update-checker>=0.16->tpot) (2.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/lib/python3/dist-packages (from pandas>=0.24.2->tpot) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas>=0.24.2->tpot) (2019.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.25.8)\n",
      "Installing collected packages: tpot\n",
      "Successfully installed tpot-0.11.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from tpot import TPOTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "A pipeline has not yet been optimized. Please call fit() first.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                 self._pop, _ = eaMuPlusLambda(\n\u001b[0m\u001b[1;32m    817\u001b[0m                     \u001b[0mpopulation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tpot/gp_deap.py\u001b[0m in \u001b[0;36meaMuPlusLambda\u001b[0;34m(population, toolbox, mu, lambda_, cxpb, mutpb, ngen, pbar, stats, halloffame, verbose, per_generation_function, log_file)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36m_evaluate_individuals\u001b[0;34m(self, population, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m   1530\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop_by_max_time_mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m                     val = partial_wrapped_cross_val_score(\n\u001b[0m\u001b[1;32m   1532\u001b[0m                         \u001b[0msklearn_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msklearn_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/stopit/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0;31m# ``result`` may not be assigned below in case of timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tpot/gp_deap.py\u001b[0m in \u001b[0;36m_wrapped_cross_val_score\u001b[0;34m(sklearn_pipeline, features, target, cv, scoring_function, sample_weight, groups, use_dask)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m     \u001b[0mcv_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0my_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             raise ValueError(\"n_splits=%d cannot be greater than the\"\n\u001b[0m\u001b[1;32m    663\u001b[0m                              \u001b[0;34m\" number of members in each class.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_splits=5 cannot be greater than the number of members in each class.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ebe43749b3dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                          \u001b[0mpopulation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#number of individuals to train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                          cv=5) #number of folds in StratifiedKFold\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpipeline_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#fit the pipeline optimizer - can take a long time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#print scoring for the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpipeline_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tpot_exported_pipeline.py'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#export the pipeline - in Python code!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    861\u001b[0m                     \u001b[0;31m# raise the exception if it's our last attempt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    852\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                     \u001b[0;31m# Delete the temporary cache before exiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tpot/base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0;31m# If user passes CTRL+C in initial generation, self._pareto_front (halloffame) shoule be not updated yet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0;31m# need raise RuntimeError because no pipeline has been optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    962\u001b[0m                 \u001b[0;34m\"A pipeline has not yet been optimized. Please call fit() first.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A pipeline has not yet been optimized. Please call fit() first."
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline_optimizer = TPOTClassifier(generations=5, #number of iterations to run the training\n",
    "                                         population_size=20, #number of individuals to train\n",
    "                                         cv=5) #number of folds in StratifiedKFold\n",
    "pipeline_optimizer.fit(X_train, y_train) #fit the pipeline optimizer - can take a long time\n",
    "print(pipeline_optimizer.score(X_test, y_test)) #print scoring for the pipeline\n",
    "pipeline_optimizer.export('tpot_exported_pipeline.py') #export the pipeline - in Python code!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = d['ArrDelay']\n",
    "X = d.drop('ArrDelay', axis = 'columns')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model = MyAutoMLClassifier()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_pipeline"
   ]
  }
 ]
}